{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMYevNJsrur9TwxZfMMzFml",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OttmarIvey/APP-de-Audiolibros-con-TensorFlow/blob/main/APP_de_Audiolibros_con_TensorFlow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Oe-iutGpnlTR"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn import preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cargar los datos\n"
      ],
      "metadata": {
        "id": "gDqvmirv6dpv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datos_sin_procesar = np.loadtxt('Audiobooks_data.csv',delimiter=',')\n",
        "datos_sin_procesar"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TExzWWdu5qj-",
        "outputId": "f67b8987-a547-4436-8304-1929b07d42a5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[8.7300e+02, 2.1600e+03, 2.1600e+03, ..., 0.0000e+00, 0.0000e+00,\n",
              "        1.0000e+00],\n",
              "       [6.1100e+02, 1.4040e+03, 2.8080e+03, ..., 0.0000e+00, 1.8200e+02,\n",
              "        1.0000e+00],\n",
              "       [7.0500e+02, 3.2400e+02, 3.2400e+02, ..., 1.0000e+00, 3.3400e+02,\n",
              "        1.0000e+00],\n",
              "       ...,\n",
              "       [2.8671e+04, 1.0800e+03, 1.0800e+03, ..., 0.0000e+00, 2.9000e+01,\n",
              "        0.0000e+00],\n",
              "       [3.1134e+04, 2.1600e+03, 2.1600e+03, ..., 0.0000e+00, 0.0000e+00,\n",
              "        0.0000e+00],\n",
              "       [3.2832e+04, 1.6200e+03, 1.6200e+03, ..., 0.0000e+00, 9.0000e+01,\n",
              "        0.0000e+00]])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extraemos las columnas excluyendo la primera y la ultima columna\n",
        "todas_entradas_no_escaladas = datos_sin_procesar[:,1:-1]\n",
        "\n",
        "#Extraemos la ultima columna, la cual contiene nuestros objetivos\n",
        "todos_objetivos = datos_sin_procesar[:,-1]"
      ],
      "metadata": {
        "id": "YWkDXDIW6ytG"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Equilibremos el conjunto de datos"
      ],
      "metadata": {
        "id": "9SYArZm88aAQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Contaremos el numero de objetivos que son 1 y mantendremos unicamente los objetivos igual a 1 y 0\n",
        "num_objetivos_uno = int(np.sum(todos_objetivos)) # Numero de objetivos que son 1 ya que es el unico valor distinto de 0\n",
        "contador_objetivos_cero = 0\n",
        "indices_a_remover = []\n",
        "\n",
        "for i in range(todos_objetivos.shape[0]): # Su forma en el eje cero es la longitud del vector\n",
        "   #Queremos aumentar el contador en 1 si el objetivo es 0\n",
        "   if todos_objetivos[i] == 0:\n",
        "    contador_objetivos_cero += 1\n",
        "    #Añadimos un indice a la variable indices a remover si el contador de ceros es mayor\n",
        "    # al numero de 1\n",
        "    if contador_objetivos_cero > num_objetivos_uno:\n",
        "      indices_a_remover.append(i)\n",
        "\n",
        "#Ahora crearemos una variable con las entradas no escaladas menos aquellas en la variable indices a remover\n",
        "entradas_no_escaladas_con_previas_iguales = np.delete(todas_entradas_no_escaladas,indices_a_remover,axis=0)\n",
        "\n",
        "#De igual forma creamos la varriable con los objetivos\n",
        "objetivos_con_previas_iguales = np.delete(todos_objetivos,indices_a_remover,axis=0)"
      ],
      "metadata": {
        "id": "vqP1o5_T73a6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Escalar las entradas"
      ],
      "metadata": {
        "id": "ImrZ0nJsAwLd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Con ayuda de la blibioteca de preprocesamiento importada de SkLearn escalamos los datos\n",
        "entradas_escaladas = preprocessing.scale(entradas_no_escaladas_con_previas_iguales)"
      ],
      "metadata": {
        "id": "ncrA_TDxAvxX"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Permutacion de los datos"
      ],
      "metadata": {
        "id": "DiGUKyK3Fp6u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Conviene permutar los datos de forma aleatoria para poder hacer el analis por lotes.\n",
        "#Primero ptomamos los indices de la forma entradas escaladas y los almacenamos en una variable\n",
        "indices_permutados = np.arange(entradas_escaladas.shape[0])\n",
        "np.random.shuffle(indices_permutados)\n",
        "\n",
        "# Luego creamos las variables entradas y objetivos permutados, donde sus indices son los indices permutados\n",
        "entradas_permutadas = entradas_escaladas[indices_permutados]\n",
        "objetivos_permutados = objetivos_con_previas_iguales[indices_permutados]"
      ],
      "metadata": {
        "id": "e9p8Nl0A-pko"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dividir el conjunto de datos en \"entrenamiento\", \"validacion\" y \"prueba\""
      ],
      "metadata": {
        "id": "70zCaUgQH1lV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Contaremos el numero total de muestras, el cual es igual a la forma de las entradas permutadas en el eje cero\n",
        "cuenta_muestras = entradas_permutadas.shape[0]\n",
        "\n",
        "# Usaremos la divison de datos 80-10-10 para el entrenamiento, validacion y prueba\n",
        "cuenta_muestras_entrenamiento = int(0.8*cuenta_muestras)\n",
        "cuenta_muestras_validacion = int(0.1*cuenta_muestras)\n",
        "cuenta_muestras_prueba = cuenta_muestras - cuenta_muestras_entrenamiento - cuenta_muestras_validacion\n",
        "\n",
        "#Ahora que tenemos los tamaños de entrenamiento, validacion y prueba los extraeremos del conjunto de datos\n",
        "#Entradas y objetivos de entrenamiento:\n",
        "entradas_entrenamiento = entradas_permutadas[:cuenta_muestras_entrenamiento]\n",
        "objetivos_entrenamiento = objetivos_permutados[:cuenta_muestras_entrenamiento]\n",
        "\n",
        "#Entradas y objetivos de validacion:\n",
        "entradas_validacion = entradas_permutadas[cuenta_muestras_entrenamiento+cuenta_muestras_validacion]\n",
        "objetivos_validacion = objetivos_permutados[cuenta_muestras_entrenamiento:cuenta_muestras_entrenamiento+cuenta_muestras_validacion]\n",
        "\n",
        "#Entradas y objetivos de prueba:\n",
        "entradas_prueba = entradas_permutadas[cuenta_muestras_entrenamiento+cuenta_muestras_validacion:]\n",
        "objetivos_prueba = objetivos_permutados[cuenta_muestras_entrenamiento+cuenta_muestras_validacion]\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "h47sNx7ZH0bo"
      },
      "execution_count": 9,
      "outputs": []
    }
  ]
}